{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f49704-bc13-4749-8c5a-7bc5ee48d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 12:57:13,127 - __main__ - INFO - Loading model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
      "2025-01-25 12:57:30,116 - __main__ - INFO - Model and tokenizer loaded successfully.\n",
      "2025-01-25 12:57:32,296 - __main__ - INFO - Bot is starting...\n",
      "2025-01-25 12:57:32,529 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getMe \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot is running. Stop the kernel to terminate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 12:57:32,572 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/deleteWebhook \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:57:32,576 - telegram.ext.Application - INFO - Application started\n",
      "2025-01-25 12:57:37,882 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:57:38,022 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:57:47,933 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:57:56,892 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:57:56,894 - __main__ - INFO - Received message: Tell me about whales\n",
      "2025-01-25 12:58:08,618 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:58:18,657 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:58:28,716 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:58:33,900 - __main__ - WARNING - Retrying with a simplified prompt...\n",
      "2025-01-25 12:58:38,781 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:58:48,830 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:58:58,876 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:08,919 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:18,965 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:29,012 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:39,045 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:49,085 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 12:59:59,148 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:09,219 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:19,262 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:29,304 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:29,819 - __main__ - INFO - Constructed Prompt: Write a detailed and informative explanation about Whales, including examples and interesting facts.\n",
      "2025-01-25 13:00:29,821 - __main__ - INFO - Model Output: Tell me all you know about Whales.\n",
      "\n",
      "Whale: (smiling) I've been studying whales for over 20 years. I've seen them in their natural habitat, and I've even been able to communicate with them.\n",
      "\n",
      "Jake: (surprised) That's incredible! How did you learn to communicate with whales?\n",
      "\n",
      "Whale: (laughs) It's not that easy. Whales have a complex communication system, and it's not always easy to understand. But I've learned to listen carefully and to pay attention to the subtle signals that whales use to communicate.\n",
      "\n",
      "Jake: (impressed) That's amazing. How do you use that knowledge to help save whales?\n",
      "\n",
      "Whale: (smiling) Well, I've been working with a group of scientists to develop a new technology that can help us better understand the behavior of whales. By using this technology, we can better predict when and where whales are most likely to be in danger.\n",
      "\n",
      "Jake: (interested) That's really cool. How does this technology work?\n",
      "\n",
      "Whale: (explains) We're using a specialized device that can detect the electrical signals that whales use to communicate. By analyzing these signals, we can identify patterns and trends that help us predict when and\n",
      "2025-01-25 13:00:29,836 - __main__ - INFO - Generated response: Tell me all you know about Whales.\n",
      "\n",
      "Whale: (smiling) I've been studying whales for over 20 years. I've seen them in their natural habitat, and I've even been able to communicate with them.\n",
      "\n",
      "Jake: (surprised) That's incredible! How did you learn to communicate with whales?\n",
      "\n",
      "Whale: (laughs) It's not that easy. Whales have a complex communication system, and it's not always easy to understand. But I've learned to listen carefully and to pay attention to the subtle signals that whales use to communicate.\n",
      "\n",
      "Jake: (impressed) That's amazing. How do you use that knowledge to help save whales?\n",
      "\n",
      "Whale: (smiling) Well, I've been working with a group of scientists to develop a new technology that can help us better understand the behavior of whales. By using this technology, we can better predict when and where whales are most likely to be in danger.\n",
      "\n",
      "Jake: (interested) That's really cool. How does this technology work?\n",
      "\n",
      "Whale: (explains) We're using a specialized device that can detect the electrical signals that whales use to communicate. By analyzing these signals, we can identify patterns and trends that help us predict when and\n",
      "2025-01-25 13:00:30,116 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:39,345 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:49,398 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:00:59,429 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:09,482 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:19,517 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:29,549 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:39,590 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:49,626 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:01:59,681 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:09,715 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:19,754 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:29,788 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:39,826 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:49,862 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:02:59,894 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:05,957 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:05,980 - __main__ - INFO - Received message: Tell me about Panda\n",
      "2025-01-25 13:03:12,452 - __main__ - WARNING - Retrying with a simplified prompt...\n",
      "2025-01-25 13:03:16,132 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:18,934 - __main__ - INFO - Constructed Prompt: Write a detailed and informative explanation about Panda, including examples and interesting facts.\n",
      "2025-01-25 13:03:18,938 - __main__ - INFO - Model Output: Tell me all you know about Panda.\n",
      "2025-01-25 13:03:18,952 - __main__ - INFO - Generated response: Tell me all you know about Panda.\n",
      "2025-01-25 13:03:19,353 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:26,282 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:27,759 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:28,086 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:37,943 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:39,554 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:39,558 - __main__ - INFO - Received message: Tell me about panda\n",
      "2025-01-25 13:03:47,324 - __main__ - WARNING - Retrying with a simplified prompt...\n",
      "2025-01-25 13:03:49,687 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:49,723 - __main__ - INFO - Constructed Prompt: Write a detailed and informative explanation about Panda, including examples and interesting facts.\n",
      "2025-01-25 13:03:49,725 - __main__ - INFO - Model Output: Tell me all you know about Panda.\n",
      "2025-01-25 13:03:49,732 - __main__ - INFO - Generated response: Tell me all you know about Panda.\n",
      "2025-01-25 13:03:49,966 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/sendMessage \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:03:59,754 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:04:09,788 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:04:19,824 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:04:29,882 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:04:39,930 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:04:49,972 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:00,012 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:10,050 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:20,083 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:30,117 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:40,156 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:05:50,188 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:00,243 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:10,279 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:20,322 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:30,355 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:40,391 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:06:50,425 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:07:00,465 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:07:00,500 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE/getUpdates \"HTTP/1.1 200 OK\"\n",
      "2025-01-25 13:07:00,504 - telegram.ext.Application - INFO - Application is stopping. This might take a moment.\n",
      "2025-01-25 13:07:00,507 - telegram.ext.Application - INFO - Application.stop() complete\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot close a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 100\u001b[0m\n\u001b[0;32m     97\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mrun_until_complete(application\u001b[38;5;241m.\u001b[39mrun_polling())\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Run the bot\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m \u001b[43mrun_bot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 97\u001b[0m, in \u001b[0;36mrun_bot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot is starting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBot is running. Stop the kernel to terminate.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m asyncio\u001b[38;5;241m.\u001b[39mget_event_loop()\u001b[38;5;241m.\u001b[39mrun_until_complete(\u001b[43mapplication\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_polling\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science_env\\Lib\\site-packages\\telegram\\ext\\_application.py:868\u001b[0m, in \u001b[0;36mApplication.run_polling\u001b[1;34m(self, poll_interval, timeout, bootstrap_retries, read_timeout, write_timeout, connect_timeout, pool_timeout, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_callback\u001b[39m(exc: TelegramError) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_error(error\u001b[38;5;241m=\u001b[39mexc, update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m--> 868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mupdater_coroutine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdater\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_polling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoll_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbootstrap_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbootstrap_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnect_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallowed_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_pending_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_pending_updates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if there is an error in fetching updates\u001b[39;49;00m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclose_loop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclose_loop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_signals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science_env\\Lib\\site-packages\\telegram\\ext\\_application.py:1099\u001b[0m, in \u001b[0;36mApplication.__run\u001b[1;34m(self, updater_coroutine, stop_signals, close_loop)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m close_loop:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\data_science_env\\Lib\\asyncio\\selector_events.py:88\u001b[0m, in \u001b[0;36mBaseSelectorEventLoop.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_running():\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot close a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_closed():\n\u001b[0;32m     90\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot close a running event loop"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from telegram import Update\n",
    "from tqdm import tqdm\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import logging\n",
    "import asyncio\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "TELEGRAM_TOKEN = '7027664349:AAGle-6J7OonsOjCrG7aRaH4aBADDT1btBE'  # Replace with your bot's API token\n",
    "\n",
    "# Load TinyLlama model and tokenizer\n",
    "try:\n",
    "    model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"  # Replace with the exact TinyLlama model path\n",
    "    logger.info(f\"Loading model: {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "    # Set the padding token (TinyLlama models may not define a pad token by default)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    logger.info(\"Model and tokenizer loaded successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model or tokenizer: {e}\")\n",
    "    raise e\n",
    "\n",
    "def process_with_tinyllama(prompt):\n",
    "    \"\"\"\n",
    "    Processes user input with TinyLlama and generates a detailed response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Clean and simplify the prompt\n",
    "        topic = prompt.lower().replace(\"tell me about\", \"\").strip()\n",
    "        enhanced_prompt = f\"Write a detailed and informative explanation about {topic.capitalize()}, including examples and interesting facts.\"\n",
    "\n",
    "        # Tokenize input and create attention mask\n",
    "        inputs = tokenizer(enhanced_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs[\"attention_mask\"] = (inputs[\"input_ids\"] != tokenizer.pad_token_id).long()\n",
    "\n",
    "        # Generate output\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=300,\n",
    "            temperature=1.2,\n",
    "            top_p=0.95,\n",
    "            top_k=50,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "        )\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Retry with a simplified prompt if the response is unsatisfactory\n",
    "        if not response.strip() or response.lower() == enhanced_prompt.lower():\n",
    "            logger.warning(\"Retrying with a simplified prompt...\")\n",
    "            fallback_prompt = f\"Tell me all you know about {topic.capitalize()}.\"\n",
    "            inputs = tokenizer(fallback_prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "            outputs = model.generate(\n",
    "                inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_length=300,\n",
    "                temperature=1.0,\n",
    "                top_p=0.9,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "            )\n",
    "            response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Log details for debugging\n",
    "        logger.info(f\"Constructed Prompt: {enhanced_prompt}\")\n",
    "        logger.info(f\"Model Output: {response}\")\n",
    "\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during TinyLlama processing: {e}\")\n",
    "        return \"Sorry, an error occurred while processing your request.\"\n",
    "\n",
    "# Main function\n",
    "def run_bot():\n",
    "    \"\"\"\n",
    "    Creates and runs the Telegram bot application.\n",
    "    \"\"\"\n",
    "    application = Application.builder().token(TELEGRAM_TOKEN).build()\n",
    "\n",
    "    # Command and message handlers\n",
    "    application.add_handler(CommandHandler(\"start\", start))\n",
    "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, echo))\n",
    "\n",
    "    logger.info(\"Bot is starting...\")\n",
    "    print(\"Bot is running. Stop the kernel to terminate.\")\n",
    "    asyncio.get_event_loop().run_until_complete(application.run_polling())\n",
    "\n",
    "# Run the bot\n",
    "run_bot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037ef1f-9d51-4f31-8a7a-e3796b560ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8021cb6b-aaf0-4e36-991e-22dcd40399d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (data_science_env)",
   "language": "python",
   "name": "data_science_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
